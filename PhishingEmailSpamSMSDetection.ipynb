{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2314712,"sourceType":"datasetVersion","datasetId":1396839},{"sourceId":7263127,"sourceType":"datasetVersion","datasetId":1522783},{"sourceId":8502378,"sourceType":"datasetVersion","datasetId":5074342},{"sourceId":9440000,"sourceType":"datasetVersion","datasetId":5736412}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Introduction\n\nThis spam and phishing detection tool was developed as part of **Chapter 5: Practical AI using ML and LM** of my Master's thesis titled *Practical AI in Cyberwarfare and Cybersecurity*.\n\nCreated by **Konstantinos Zafeiropoulos (ID: 20390293)**  \n**University of West Attica**  \n**Faculty of Engineering, Department of Informatics and Computer Engineering*\n\nThe tool applies **machine learning and NLP** to classify messages as *spam* or *ham*, including phishing detection. It uses **TF-IDF vectorization** and a **Logistic Regression** classifier trained on real-world datasets. The system is fast, lightweight and effective for real-time filtering applications.\n","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Download stopwords\nnltk.download(\"stopwords\")\n\n# Load datasets\ndf_sms = pd.read_csv(\"/kaggle/input/spam-sms-classification-using-nlp/Spam_SMS.csv\")\ndf_sms.columns = [\"Category\", \"Message\"]\n\ndf_email = pd.read_csv(\"/kaggle/input/spam-email-classification/email.csv\")\ndf_email.columns = [\"Category\", \"Message\"]\n\ndf_uci_sms = pd.read_csv(\"/kaggle/input/uci-sms-spam-collection-data-set/SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"Category\", \"Message\"])\n\n# Load phishing email datasets\npaths = [\n    \"/kaggle/input/phishing-email-dataset/CEAS_08.csv\",\n    \"/kaggle/input/phishing-email-dataset/Enron.csv\",\n    \"/kaggle/input/phishing-email-dataset/Ling.csv\",\n    \"/kaggle/input/phishing-email-dataset/Nazario.csv\",\n    \"/kaggle/input/phishing-email-dataset/Nigerian_Fraud.csv\",\n    \"/kaggle/input/phishing-email-dataset/SpamAssasin.csv\",\n    \"/kaggle/input/phishing-email-dataset/phishing_email.csv\"\n]\n\nphishing_dfs = []\nfor path in paths:\n    try:\n        df_temp = pd.read_csv(path)\n        df_temp = df_temp.iloc[:, :2]\n        df_temp.columns = [\"Category\", \"Message\"]\n        phishing_dfs.append(df_temp)\n    except Exception as e:\n        print(f\"‚ùå Error loading {path}: {e}\")\n\n# Combine all datasets\ndf = pd.concat([df_sms, df_email, df_uci_sms] + phishing_dfs, ignore_index=True)\ndf.dropna(subset=[\"Category\", \"Message\"], inplace=True)\n\n# Clean and encode labels\ndf[\"Category\"] = df[\"Category\"].astype(str).str.lower().str.strip()\ndf = df[df[\"Category\"].isin([\"spam\", \"ham\"])]\ndf[\"Category\"] = df[\"Category\"].map({\"spam\": 0, \"ham\": 1})\ndf.dropna(inplace=True)\n\nprint(f\"üì¶ Total Samples Before Balancing: {df.shape[0]}\")\n\n# Visualize original distribution\nsns.countplot(data=df, x=\"Category\")\nplt.title(\"Original Distribution of Spam vs Ham\")\nplt.show()\n\n# Balance the dataset (undersampling)\nspam_df = df[df[\"Category\"] == 0]\nham_df = df[df[\"Category\"] == 1].sample(len(spam_df), random_state=42)\ndf_balanced = pd.concat([spam_df, ham_df]).sample(frac=1, random_state=42)\n\nprint(f\"üì¶ Total Samples After Balancing: {df_balanced.shape[0]}\")\n\n# Visualize balanced data\nsns.countplot(data=df_balanced, x=\"Category\")\nplt.title(\"Balanced Spam vs Ham Distribution\")\nplt.show()\n\n# Train/test split on balanced data\nX = df_balanced[\"Message\"]\nY = df_balanced[\"Category\"]\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n\n# TF-IDF vectorization\nvectorizer = TfidfVectorizer(min_df=1, stop_words=\"english\", lowercase=True)\nX_train_features = vectorizer.fit_transform(X_train)\nX_test_features = vectorizer.transform(X_test)\n\n# Train model\nmodel = LogisticRegression()\nmodel.fit(X_train_features, Y_train)\n\n# Evaluate model\ntrain_pred = model.predict(X_train_features)\ntest_pred = model.predict(X_test_features)\n\nprint(\"üìà Accuracy on training data:\", accuracy_score(Y_train, train_pred))\nprint(\"üìä Accuracy on testing data:\", accuracy_score(Y_test, test_pred))\n\n# Confusion matrix\ncm = confusion_matrix(Y_test, test_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:51:34.054242Z","iopub.execute_input":"2025-06-11T20:51:34.054492Z","iopub.status.idle":"2025-06-11T20:51:45.407453Z","shell.execute_reply.started":"2025-06-11T20:51:34.054469Z","shell.execute_reply":"2025-06-11T20:51:45.406586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test the model\nnew_messages = [\"Congratulations! You have won a free ticket to Bahamas! Click here.\",\n                \"Hey are we still on for lunch today?\"]\nnew_features = vectorizer.transform(new_messages)\npredictions = model.predict(new_features)\n\nfor msg, pred in zip(new_messages, predictions):\n    label = \"Ham\" if pred == 1 else \"Spam\"\n    print(f\"Message: {msg}\\nPrediction: {label}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:52:15.355023Z","iopub.execute_input":"2025-06-11T20:52:15.355329Z","iopub.status.idle":"2025-06-11T20:52:15.362480Z","shell.execute_reply.started":"2025-06-11T20:52:15.355306Z","shell.execute_reply":"2025-06-11T20:52:15.361811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\ndef predict_message(msg):\n    features = vectorizer.transform([msg])\n    \n    start_time = time.time()  # ‚è± Start timer\n    result = model.predict(features)[0]\n    end_time = time.time()    # ‚è± End timer\n\n    label = \"Ham\" if result == 1 else \"Spam\"\n    duration = (end_time - start_time) * 1000  # in milliseconds\n    print(f\"üîç Message: {msg}\")\n    print(f\"‚û°Ô∏è Prediction: {label}\")\n    print(f\"‚è± Prediction Time: {duration:.4f} ms\")\n\nuser_msg = input(\"‚úâÔ∏è Enter a message to check: \")\npredict_message(user_msg)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:52:22.630200Z","iopub.execute_input":"2025-06-11T20:52:22.630470Z","iopub.status.idle":"2025-06-11T20:53:10.213916Z","shell.execute_reply.started":"2025-06-11T20:52:22.630450Z","shell.execute_reply":"2025-06-11T20:53:10.213316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(Y_test, test_pred, target_names=[\"Spam\", \"Ham\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:53:30.219848Z","iopub.execute_input":"2025-06-11T20:53:30.220489Z","iopub.status.idle":"2025-06-11T20:53:30.232240Z","shell.execute_reply.started":"2025-06-11T20:53:30.220465Z","shell.execute_reply":"2025-06-11T20:53:30.231569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Most common spam words\nstop_words = set(stopwords.words(\"english\"))\nspam_words = \" \".join(df[df['Category'] == 0]['Message']).split()\nword_freq = Counter([word.lower() for word in spam_words if word.lower() not in stop_words and word.isalpha()])\n\nplt.figure(figsize=(10, 6))\nplt.bar(*zip(*word_freq.most_common(7)), color='orange')\nplt.title(\"Top 7 Most Common Words in Spam Messages\")\nplt.xlabel(\"Words\")\nplt.ylabel(\"Frequency\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:53:18.025455Z","iopub.execute_input":"2025-06-11T20:53:18.025995Z","iopub.status.idle":"2025-06-11T20:53:18.213934Z","shell.execute_reply.started":"2025-06-11T20:53:18.025973Z","shell.execute_reply":"2025-06-11T20:53:18.213148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Explainability, Reducing AI Risks\n\nimport shap\n\n# Convert sparse matrix to dense\nX_sample_dense = X_test_features[:5].toarray()\n\n# Use LinearExplainer for LogisticRegression\nexplainer = shap.Explainer(model, X_train_features[:100].toarray())  # small background for performance\nshap_values = explainer(X_sample_dense)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:58:00.193019Z","iopub.execute_input":"2025-06-11T20:58:00.193837Z","iopub.status.idle":"2025-06-11T20:58:00.211705Z","shell.execute_reply.started":"2025-06-11T20:58:00.193812Z","shell.execute_reply":"2025-06-11T20:58:00.210877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get TF-IDF feature names\nfeature_names = vectorizer.get_feature_names_out()\n\n# Get mean absolute SHAP values\nimport numpy as np\nmean_shap_values = np.abs(shap_values.values).mean(axis=0)\n\n# Create DataFrame mapping feature indices to words\nimport pandas as pd\nshap_df = pd.DataFrame({\n    'Word': feature_names,\n    'Mean SHAP Value': mean_shap_values\n})\n\n# Sort and display top 20 most influential words\nshap_df_sorted = shap_df.sort_values(by='Mean SHAP Value', ascending=False).head(20)\nprint(shap_df_sorted)\n\n# Plot top SHAP words\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.barh(shap_df_sorted['Word'], shap_df_sorted['Mean SHAP Value'], color='orange')\nplt.xlabel(\"Mean |SHAP Value|\")\nplt.title(\"Top 20 Words Influencing Spam Classification\")\nplt.gca().invert_yaxis()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T20:58:01.961903Z","iopub.execute_input":"2025-06-11T20:58:01.962507Z","iopub.status.idle":"2025-06-11T20:58:02.188237Z","shell.execute_reply.started":"2025-06-11T20:58:01.962480Z","shell.execute_reply":"2025-06-11T20:58:02.187564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_real_email():\n    import time\n\n    # üîπ Ask user to paste their email\n    print(\"üì• Paste the full email content below (e.g., subject + body):\\n\")\n    email_text = input(\"‚úâÔ∏è Email: \")\n\n    # üîπ Transform with vectorizer\n    features = vectorizer.transform([email_text])\n\n    # üîπ Predict\n    start_time = time.time()\n    result = model.predict(features)[0]\n    end_time = time.time()\n\n    # üîπ Interpret result\n    label = \"‚úÖ Ham (Safe Message)\" if result == 1 else \"‚ö†Ô∏è Spam/Phishing\"\n    print(\"\\nüì® Email Content Preview:\")\n    print(\"-\" * 60)\n    print(email_text[:300] + (\"...\" if len(email_text) > 300 else \"\"))\n    print(\"-\" * 60)\n    print(f\"üîé Prediction: {label}\")\n    print(f\"‚è± Prediction Time: {(end_time - start_time)*1000:.2f} ms\")\n\n# Call this to test\ntest_real_email()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T21:18:01.857042Z","iopub.execute_input":"2025-06-11T21:18:01.857756Z","iopub.status.idle":"2025-06-11T21:18:03.278364Z","shell.execute_reply.started":"2025-06-11T21:18:01.857735Z","shell.execute_reply":"2025-06-11T21:18:03.277658Z"}},"outputs":[],"execution_count":null}]}